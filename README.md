# ğŸ§  RAG_HEITAA: AI-Powered Healthcare Query Assistant

**RAG_HEITAA** is a modular Retrieval-Augmented Generation (RAG) system designed as a plug-in intelligence layer for the larger HEITa healthcare expense assistant platform.

---

## ğŸš¨ Problem We're Addressing

Healthcare billing in the U.S. is fragmented, opaque, and error-prone:
- 30â€“80% of bills contain costly mistakes.
- Over 100M Americans canâ€™t afford unexpected medical bills.
- Patients lack tools to understand, verify, or dispute charges.

### ğŸ§© HEITa Vision
HEITa (Healthcare Expense Information Tracking Assistant) is an AI-driven platform that will:
- Parse bills & claims
- Detect discrepancies
- Empower patients to understand and act
- Offer seamless voice/chat-based navigation

---

## ğŸ” Purpose of This Module

This project represents the **RAG-based query module** (RAG_HEITAA) that powers intelligent Q&A over structured health documents (e.g., EOBs, claims, notes).

It is designed to:
- Accept natural language queries
- Use custom embeddings for document indexing
- Retrieve relevant context using a vector store
- Enable future integration with voice-based flows

---

## ğŸ—ï¸ Project Structure

```
rag_new/
â”œâ”€â”€ chat_engine/
â”‚   â””â”€â”€ chat_engine.py         # Core RAG assistant logic
â”‚   â””â”€â”€ modules/
â”‚       â””â”€â”€ retriever.py       # Query interface with vector store
â”œâ”€â”€ vector_store/
â”‚   â”œâ”€â”€ base.py                # Public API: init, index, query
â”‚   â”œâ”€â”€ interfaces.py          # Abstract base class: VectorDB
â”‚   â””â”€â”€ backends/
â”‚       â””â”€â”€ qdrant_store.py    # Qdrant-backed vector DB implementation
â”œâ”€â”€ main.py                    # CLI runner to test the assistant
â””â”€â”€ README.md                  # â† You're here
```

---

## ğŸ§  RAG Strategy

- **Embedding Model:** Your LLM or embedding model generates document vectors.
- **Vector Store Abstraction:** Supports plug-and-play backends like Qdrant or FAISS via `VectorDB` interface.
- **Decoupled Logic:** Core application doesn't need to know which DB is used â€” just calls `index_document()` and `query_vector()`.

---

## ğŸš€ Getting Started

### 1. Install dependencies
```bash
pip install -r requirements.txt
```

### 2. Run Qdrant (via Docker)
```bash
docker run -p 6333:6333 -p 6334:6334 qdrant/qdrant
```

### 3. Run the assistant
```bash
python main.py
```

You can then ask questions like:
> â€œWhat happened to my insurance claim?â€

---

## ğŸ“¦ Vector Storage Abstraction

RAG_HEITAA introduces an extensible vector DB architecture:

```python
# Example interface method call
index_document(doc_id="123", vector=[...], payload={"text": "Claim denied"})
results = query_vector(vector=[...], top_k=3)
```

Internally, these delegate to a backend implementation like `QdrantVectorStore`.

---

## ğŸ›£ï¸ Future Roadmap

âœ… Modular vector backend (Qdrant)  
âœ… Working retrieval pipeline  
ğŸŸ¡ Integration with EOB/claim data  
ğŸŸ¡ Voice command support  
ğŸŸ¡ In-memory fallback for fast prototyping  
ğŸŸ¢ Plug-in into HEITa Phase 1 MVP flows

---

## ğŸ¤ Contributing

This module is part of the HEITa initiative. If you'd like to improve it or plug in alternative vector DBs (e.g., FAISS, Pinecone), feel free to extend the `VectorDB` interface.
